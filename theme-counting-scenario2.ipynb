{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "   session_id                                  walmart_complaint\n",
      "0           1  The checkout lines are always too long and the...\n",
      "1           2  Customer service is terrible, staff are rude a...\n",
      "2           3  Store is always messy and items are never wher...\n",
      "3           4     Prices keep going up but quality is going down\n",
      "4           5  Self-checkout machines are always broken and t...\n",
      "Starting Walmart complaint analysis...\n",
      "Processing 5 complaints...\n",
      "Processing batch 1 (5 complaints)...\n",
      "Results saved to walmart_analysis_results.json\n",
      "\n",
      "\n",
      "WALMART COMPLAINT ANALYSIS REPORT\n",
      "================================\n",
      "\n",
      "OVERVIEW:\n",
      "- Total Complaints Analyzed: 5\n",
      "- Processing Batches: 1\n",
      "- Categories Identified: 4\n",
      "- Topics Identified: 2\n",
      "\n",
      "TOP COMPLAINT CATEGORIES:\n",
      "- Customer Service: 1 complaints\n",
      "- Store Operations: 1 complaints\n",
      "- Value Proposition: 1 complaints\n",
      "- Technology: 1 complaints\n",
      "\n",
      "TOP TOPICS:\n",
      "- Staffing Levels: 1 mentions\n",
      "- Service Quality: 1 mentions\n",
      "\n",
      "KEY RECOMMENDATIONS:\n",
      "1. Implement new staffing model based on peak hours\n",
      "2. Launch comprehensive employee training program\n",
      "3. Establish regular maintenance schedule for self-checkout systems\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "class WalmartTopicExtractor:\n",
    "    \"\"\"\n",
    "    Complete topic extraction system using CREST framework for Walmart complaints\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def clean_complaints(self, complaints: List[str]) -> List[str]:\n",
    "        \"\"\"Clean and filter complaints\"\"\"\n",
    "        cleaned = []\n",
    "        for complaint in complaints:\n",
    "            if isinstance(complaint, str) and len(complaint.strip()) > 10:\n",
    "                # Basic cleaning\n",
    "                clean_text = re.sub(r'\\s+', ' ', complaint.strip())\n",
    "                cleaned.append(clean_text)\n",
    "        return cleaned\n",
    "    \n",
    "    def create_crest_prompt(self, complaints: List[str]) -> str:\n",
    "        \"\"\"Create comprehensive CREST framework prompt\"\"\"\n",
    "        complaints_text = \"\\n\".join([f\"{i+1}. {complaint}\" for i, complaint in enumerate(complaints)])\n",
    "        \n",
    "        return f\"\"\"\n",
    "You are an expert retail analyst. Analyze these Walmart customer complaints using the CREST framework:\n",
    "\n",
    "COMPLAINTS:\n",
    "{complaints_text}\n",
    "\n",
    "Apply the CREST Framework:\n",
    "\n",
    "**C - CATEGORIZE**: Identify main complaint categories\n",
    "**R - RELATE**: Find patterns and relationships between complaints  \n",
    "**E - EXTRACT**: Extract specific topics, themes, and sentiment\n",
    "**S - SYNTHESIZE**: Combine findings into overarching themes\n",
    "**T - TRANSFORM**: Provide actionable insights\n",
    "\n",
    "Please provide analysis in this JSON format:\n",
    "\n",
    "{{\n",
    "  \"categorize\": {{\n",
    "    \"categories\": [\n",
    "      {{\n",
    "        \"category\": \"Customer Service\",\n",
    "        \"complaints\": [1, 2],\n",
    "        \"frequency\": 2,\n",
    "        \"description\": \"Issues with staff behavior and service quality\"\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  \"relate\": {{\n",
    "    \"patterns\": [\n",
    "      {{\n",
    "        \"pattern\": \"Staff-related issues\",\n",
    "        \"complaints\": [1, 3],\n",
    "        \"connection\": \"Multiple complaints about employee behavior\"\n",
    "      }}\n",
    "    ],\n",
    "    \"root_causes\": [\n",
    "      {{\n",
    "        \"cause\": \"Understaffing\",\n",
    "        \"manifestations\": [\"long wait times\", \"poor service\"],\n",
    "        \"affected_complaints\": [1, 2]\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  \"extract\": {{\n",
    "    \"topics\": [\n",
    "      {{\n",
    "        \"topic\": \"Checkout wait times\",\n",
    "        \"frequency\": 3,\n",
    "        \"sentiment\": \"negative\",\n",
    "        \"intensity\": \"high\",\n",
    "        \"keywords\": [\"long lines\", \"wait\", \"checkout\"]\n",
    "      }}\n",
    "    ],\n",
    "    \"sentiment_summary\": {{\n",
    "      \"overall_sentiment\": \"negative\",\n",
    "      \"positive_mentions\": 1,\n",
    "      \"negative_mentions\": 8,\n",
    "      \"neutral_mentions\": 1\n",
    "    }}\n",
    "  }},\n",
    "  \"synthesize\": {{\n",
    "    \"main_themes\": [\n",
    "      {{\n",
    "        \"theme\": \"Operational Efficiency\",\n",
    "        \"sub_themes\": [\"staffing\", \"checkout process\", \"store organization\"],\n",
    "        \"impact_score\": 8,\n",
    "        \"prevalence\": \"70%\"\n",
    "      }}\n",
    "    ],\n",
    "    \"priority_issues\": [\n",
    "      {{\n",
    "        \"issue\": \"Long checkout lines\",\n",
    "        \"impact\": \"high\",\n",
    "        \"frequency\": \"high\",\n",
    "        \"priority_score\": 9\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  \"transform\": {{\n",
    "    \"recommendations\": [\n",
    "      {{\n",
    "        \"action\": \"Increase checkout staff during peak hours\",\n",
    "        \"impact\": \"high\",\n",
    "        \"complexity\": \"medium\",\n",
    "        \"timeline\": \"immediate\"\n",
    "      }}\n",
    "    ],\n",
    "    \"metrics\": [\n",
    "      {{\n",
    "        \"metric\": \"Average checkout wait time\",\n",
    "        \"target\": \"< 5 minutes\",\n",
    "        \"measurement\": \"weekly\"\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    def call_llm(self, prompt: str, max_retries: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"Make API call to OpenRouter\"\"\"\n",
    "        payload = {\n",
    "            \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 4000\n",
    "        }\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    self.base_url,\n",
    "                    headers=self.headers,\n",
    "                    json=payload,\n",
    "                    timeout=60\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    content = result['choices'][0]['message']['content']\n",
    "                    \n",
    "                    # Try to extract JSON from response\n",
    "                    try:\n",
    "                        # Find JSON in the response\n",
    "                        json_start = content.find('{')\n",
    "                        json_end = content.rfind('}') + 1\n",
    "                        if json_start != -1 and json_end != -1:\n",
    "                            json_content = content[json_start:json_end]\n",
    "                            parsed_json = json.loads(json_content)\n",
    "                            return {\"success\": True, \"data\": parsed_json, \"raw_content\": content}\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    return {\"success\": True, \"data\": None, \"raw_content\": content}\n",
    "                \n",
    "                else:\n",
    "                    print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Request failed: {str(e)}\")\n",
    "                \n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "        \n",
    "        return {\"success\": False, \"error\": \"Failed after retries\"}\n",
    "\n",
    "    def analyze_complaints_batch(self, complaints: List[str], batch_size: int = 10) -> List[Dict]:\n",
    "        \"\"\"Analyze complaints in batches\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(complaints), batch_size):\n",
    "            batch = complaints[i:i+batch_size]\n",
    "            print(f\"Processing batch {i//batch_size + 1} ({len(batch)} complaints)...\")\n",
    "            \n",
    "            prompt = self.create_crest_prompt(batch)\n",
    "            result = self.call_llm(prompt)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                batch_result = {\n",
    "                    \"batch_number\": i//batch_size + 1,\n",
    "                    \"complaints\": batch,\n",
    "                    \"analysis\": result.get(\"data\"),\n",
    "                    \"raw_response\": result.get(\"raw_content\")\n",
    "                }\n",
    "                results.append(batch_result)\n",
    "            else:\n",
    "                print(f\"Failed to analyze batch {i//batch_size + 1}\")\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def extract_topics_from_dataframe(self, df: pd.DataFrame, complaint_column: str = 'walmart_complaint') -> Dict[str, Any]:\n",
    "        \"\"\"Main function to extract topics from DataFrame\"\"\"\n",
    "        print(\"Starting Walmart complaint analysis...\")\n",
    "        \n",
    "        # Clean and prepare data\n",
    "        complaints = df[complaint_column].dropna().tolist()\n",
    "        cleaned_complaints = self.clean_complaints(complaints)\n",
    "        \n",
    "        print(f\"Processing {len(cleaned_complaints)} complaints...\")\n",
    "        \n",
    "        # Analyze in batches\n",
    "        batch_results = self.analyze_complaints_batch(cleaned_complaints, batch_size=8)\n",
    "        \n",
    "        # Aggregate results\n",
    "        aggregated_results = self.aggregate_batch_results(batch_results)\n",
    "        \n",
    "        return {\n",
    "            \"total_complaints\": len(cleaned_complaints),\n",
    "            \"batches_processed\": len(batch_results),\n",
    "            \"aggregated_analysis\": aggregated_results,\n",
    "            \"batch_details\": batch_results\n",
    "        }\n",
    "\n",
    "    def aggregate_batch_results(self, batch_results: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Aggregate results from multiple batches\"\"\"\n",
    "        all_categories = []\n",
    "        all_topics = []\n",
    "        all_themes = []\n",
    "        all_recommendations = []\n",
    "        \n",
    "        for batch in batch_results:\n",
    "            if batch.get(\"analysis\"):\n",
    "                analysis = batch[\"analysis\"]\n",
    "                \n",
    "                # Aggregate categories\n",
    "                if \"categorize\" in analysis and \"categories\" in analysis[\"categorize\"]:\n",
    "                    all_categories.extend(analysis[\"categorize\"][\"categories\"])\n",
    "                \n",
    "                # Aggregate topics\n",
    "                if \"extract\" in analysis and \"topics\" in analysis[\"extract\"]:\n",
    "                    all_topics.extend(analysis[\"extract\"][\"topics\"])\n",
    "                \n",
    "                # Aggregate themes\n",
    "                if \"synthesize\" in analysis and \"main_themes\" in analysis[\"synthesize\"]:\n",
    "                    all_themes.extend(analysis[\"synthesize\"][\"main_themes\"])\n",
    "                \n",
    "                # Aggregate recommendations\n",
    "                if \"transform\" in analysis and \"recommendations\" in analysis[\"transform\"]:\n",
    "                    all_recommendations.extend(analysis[\"transform\"][\"recommendations\"])\n",
    "        \n",
    "        # Count and summarize\n",
    "        category_counts = Counter([cat.get(\"category\", \"Unknown\") for cat in all_categories])\n",
    "        topic_counts = Counter([topic.get(\"topic\", \"Unknown\") for topic in all_topics])\n",
    "        \n",
    "        return {\n",
    "            \"category_summary\": dict(category_counts),\n",
    "            \"topic_summary\": dict(topic_counts),\n",
    "            \"total_categories\": len(set(category_counts.keys())),\n",
    "            \"total_topics\": len(set(topic_counts.keys())),\n",
    "            \"all_themes\": all_themes,\n",
    "            \"all_recommendations\": all_recommendations,\n",
    "            \"top_categories\": category_counts.most_common(5),\n",
    "            \"top_topics\": topic_counts.most_common(10)\n",
    "        }\n",
    "\n",
    "    def save_results(self, results: Dict[str, Any], filename: str = \"walmart_topic_analysis.json\"):\n",
    "        \"\"\"Save results to JSON file\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"Results saved to {filename}\")\n",
    "\n",
    "    def create_summary_report(self, results: Dict[str, Any]) -> str:\n",
    "        \"\"\"Create a human-readable summary report\"\"\"\n",
    "        agg = results[\"aggregated_analysis\"]\n",
    "        \n",
    "        report = f\"\"\"\n",
    "WALMART COMPLAINT ANALYSIS REPORT\n",
    "================================\n",
    "\n",
    "OVERVIEW:\n",
    "- Total Complaints Analyzed: {results['total_complaints']}\n",
    "- Processing Batches: {results['batches_processed']}\n",
    "- Categories Identified: {agg['total_categories']}\n",
    "- Topics Identified: {agg['total_topics']}\n",
    "\n",
    "TOP COMPLAINT CATEGORIES:\n",
    "\"\"\"\n",
    "        \n",
    "        for category, count in agg['top_categories']:\n",
    "            report += f\"- {category}: {count} complaints\\n\"\n",
    "        \n",
    "        report += \"\\nTOP TOPICS:\\n\"\n",
    "        for topic, count in agg['top_topics']:\n",
    "            report += f\"- {topic}: {count} mentions\\n\"\n",
    "        \n",
    "        report += f\"\\nKEY RECOMMENDATIONS:\\n\"\n",
    "        for i, rec in enumerate(agg['all_recommendations'][:5], 1):\n",
    "            if isinstance(rec, dict):\n",
    "                action = rec.get('action', 'No action specified')\n",
    "                report += f\"{i}. {action}\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "# MAIN EXECUTION CODE\n",
    "def main():\n",
    "    # Your API key\n",
    "    API_KEY = \"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\"\n",
    "    \n",
    "    # Initialize extractor\n",
    "    extractor = WalmartTopicExtractor(API_KEY)\n",
    "    \n",
    "    # Load your data (replace with your actual file path)\n",
    "    # df = pd.read_csv('your_walmart_data.csv')\n",
    "    \n",
    "    # For demo purposes, create sample data\n",
    "    sample_data = {\n",
    "        'session_id': [1, 2, 3, 4, 5],\n",
    "        'walmart_complaint': [\n",
    "            \"The checkout lines are always too long and there's never enough cashiers\",\n",
    "            \"Customer service is terrible, staff are rude and unhelpful\",\n",
    "            \"Store is always messy and items are never where they should be\",\n",
    "            \"Prices keep going up but quality is going down\",\n",
    "            \"Self-checkout machines are always broken and there's no help\"\n",
    "        ]\n",
    "    }\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    \n",
    "    print(\"Sample DataFrame:\")\n",
    "    print(df[['session_id', 'walmart_complaint']].head())\n",
    "    \n",
    "    # Extract topics\n",
    "    results = extractor.extract_topics_from_dataframe(df, 'walmart_complaint')\n",
    "    \n",
    "    # Save results\n",
    "    extractor.save_results(results, \"walmart_analysis_results.json\")\n",
    "    \n",
    "    # Create and print summary report\n",
    "    summary = extractor.create_summary_report(results)\n",
    "    print(\"\\n\" + summary)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yabble-theme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
